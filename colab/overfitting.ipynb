{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kartoone/nn3/blob/main/colab/overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "444411dd-f3cc-4ffd-8fcb-aa5e29075012",
      "metadata": {
        "id": "444411dd-f3cc-4ffd-8fcb-aa5e29075012"
      },
      "outputs": [],
      "source": [
        "!git clone \"https://github.com/kartoone/nn3\"\n",
        "\n",
        "\"\"\"\n",
        "overfitting\n",
        "~~~~~~~~~~~\n",
        "\n",
        "Plot graphs to illustrate the problem of overfitting.  \n",
        "\"\"\"\n",
        "\n",
        "# Standard library\n",
        "import json\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# My library\n",
        "#sys.path.append('../src/')\n",
        "%cd nn3/src\n",
        "\n",
        "import mnist_loader\n",
        "import network2\n",
        "\n",
        "# Third-party libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def main(filename, num_epochs,\n",
        "         training_cost_xmin=200, \n",
        "         test_accuracy_xmin=200, \n",
        "         test_cost_xmin=0, \n",
        "         training_accuracy_xmin=0,\n",
        "         training_set_size=1000, \n",
        "         lmbda=0.0):\n",
        "    \"\"\"``filename`` is the name of the file where the results will be\n",
        "    stored.  ``num_epochs`` is the number of epochs to train for.\n",
        "    ``training_set_size`` is the number of images to train on.\n",
        "    ``lmbda`` is the regularization parameter.  The other parameters\n",
        "    set the epochs at which to start plotting on the x axis.\n",
        "    \"\"\"\n",
        "    run_network(filename, num_epochs, training_set_size, lmbda)\n",
        "    make_plots(filename, num_epochs, \n",
        "               training_cost_xmin,\n",
        "               test_accuracy_xmin,\n",
        "               test_cost_xmin, \n",
        "               training_accuracy_xmin,\n",
        "               training_set_size)\n",
        "                       \n",
        "def run_network(filename, num_epochs, training_set_size=1000, lmbda=0.0):\n",
        "    \"\"\"Train the network for ``num_epochs`` on ``training_set_size``\n",
        "    images, and store the results in ``filename``.  Those results can\n",
        "    later be used by ``make_plots``.  Note that the results are stored\n",
        "    to disk in large part because it's convenient not to have to\n",
        "    ``run_network`` each time we want to make a plot (it's slow).\n",
        "\n",
        "    \"\"\"\n",
        "    # Make results more easily reproducible\n",
        "    random.seed(12345678)\n",
        "    np.random.seed(12345678)\n",
        "    training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
        "    net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost())\n",
        "    net.large_weight_initializer()\n",
        "    \n",
        "    test_cost, test_accuracy, training_cost, training_accuracy \\\n",
        "        = net.SGD(training_data[:training_set_size], num_epochs, 10, 0.5,\n",
        "                  evaluation_data=test_data, lmbda = lmbda,\n",
        "                  monitor_evaluation_cost=True, \n",
        "                  monitor_evaluation_accuracy=True, \n",
        "                  monitor_training_cost=True, \n",
        "                  monitor_training_accuracy=True)\n",
        "    f = open(filename, \"w\")\n",
        "    json.dump([test_cost, test_accuracy, training_cost, training_accuracy], f)\n",
        "    f.close()\n",
        "\n",
        "def make_plots(filename, num_epochs, \n",
        "               training_cost_xmin=200, \n",
        "               test_accuracy_xmin=200, \n",
        "               test_cost_xmin=0, \n",
        "               training_accuracy_xmin=0,\n",
        "               training_set_size=1000):\n",
        "    \"\"\"Load the results from ``filename``, and generate the corresponding\n",
        "    plots. \"\"\"\n",
        "    f = open(filename, \"r\")\n",
        "    test_cost, test_accuracy, training_cost, training_accuracy \\\n",
        "        = json.load(f)\n",
        "    f.close()\n",
        "    plot_training_cost(training_cost, num_epochs, training_cost_xmin)\n",
        "    plot_test_accuracy(test_accuracy, num_epochs, test_accuracy_xmin)\n",
        "    plot_test_cost(test_cost, num_epochs, test_cost_xmin)\n",
        "    plot_training_accuracy(training_accuracy, num_epochs, \n",
        "                           training_accuracy_xmin, training_set_size)\n",
        "    plot_overlay(test_accuracy, training_accuracy, num_epochs,\n",
        "                 min(test_accuracy_xmin, training_accuracy_xmin),\n",
        "                 training_set_size)\n",
        "\n",
        "def plot_training_cost(training_cost, num_epochs, training_cost_xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(training_cost_xmin, num_epochs), \n",
        "            training_cost[training_cost_xmin:num_epochs],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([training_cost_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Cost on the training data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_test_accuracy(test_accuracy, num_epochs, test_accuracy_xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(test_accuracy_xmin, num_epochs), \n",
        "            [accuracy/100.0 \n",
        "             for accuracy in test_accuracy[test_accuracy_xmin:num_epochs]],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([test_accuracy_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Accuracy (%) on the test data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_test_cost(test_cost, num_epochs, test_cost_xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(test_cost_xmin, num_epochs), \n",
        "            test_cost[test_cost_xmin:num_epochs],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([test_cost_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Cost on the test data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_accuracy(training_accuracy, num_epochs, \n",
        "                           training_accuracy_xmin, training_set_size):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(training_accuracy_xmin, num_epochs), \n",
        "            [accuracy*100.0/training_set_size \n",
        "             for accuracy in training_accuracy[training_accuracy_xmin:num_epochs]],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([training_accuracy_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Accuracy (%) on the training data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_overlay(test_accuracy, training_accuracy, num_epochs, xmin,\n",
        "                 training_set_size):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(xmin, num_epochs), \n",
        "            [accuracy/100.0 for accuracy in test_accuracy], \n",
        "            color='#2A6EA6',\n",
        "            label=\"Accuracy on the test data\")\n",
        "    ax.plot(np.arange(xmin, num_epochs), \n",
        "            [accuracy*100.0/training_set_size \n",
        "             for accuracy in training_accuracy], \n",
        "            color='#FFA933',\n",
        "            label=\"Accuracy on the training data\")\n",
        "    ax.grid(True)\n",
        "    ax.set_xlim([xmin, num_epochs])\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylim([90, 100])\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    filename = input(\"Enter a file name: \")\n",
        "    num_epochs = int(input(\"Enter the number of epochs to run for: \"))\n",
        "    training_cost_xmin = int(input(\"training_cost_xmin (suggest 200): \"))\n",
        "    test_accuracy_xmin = int(input(\"test_accuracy_xmin (suggest 200): \"))\n",
        "    test_cost_xmin = int(input(\"test_cost_xmin (suggest 0): \"))\n",
        "    training_accuracy_xmin = int(input(\"training_accuracy_xmin (suggest 0): \"))\n",
        "    training_set_size = int(input(\"Training set size (suggest 1000): \"))\n",
        "    lmbda = float(input(\"Enter the regularization parameter, lambda (suggest: 5.0): \"))\n",
        "    main(filename, num_epochs, training_cost_xmin, \n",
        "         test_accuracy_xmin, test_cost_xmin, training_accuracy_xmin,\n",
        "         training_set_size, lmbda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f82fb7c-20ab-4535-a47b-c0921bd4284c",
      "metadata": {
        "id": "4f82fb7c-20ab-4535-a47b-c0921bd4284c"
      },
      "outputs": [],
      "source": [
        "import mnist_loader \n",
        "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
        "import network2 \n",
        "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost) \n",
        "net.large_weight_initializer()\n",
        "net.SGD(training_data[:1000], 400, 10, 0.5, evaluation_data=test_data, monitor_evaluation_cost=True, monitor_evaluation_accuracy=True, monitor_training_cost=True, monitor_training_accuracy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5537be35-dd11-4141-971f-13e773bb1280",
      "metadata": {
        "id": "5537be35-dd11-4141-971f-13e773bb1280"
      },
      "outputs": [],
      "source": [
        "net = network2.Network([784, 100, 10], cost=network2.CrossEntropyCost)\n",
        "net.large_weight_initializer()\n",
        "net.SGD(training_data, 10, 10, 0.25, lmbda=5.0, evaluation_data=validation_data, monitor_training_cost=True, monitor_evaluation_accuracy=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}