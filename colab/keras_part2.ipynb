{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kartoone/nn3/blob/main/colab/keras_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qfZQ0fhPt-1",
    "outputId": "91872509-5d80-4f25-f05c-6e91084486ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "before converting... 5\n",
      "7\n",
      "after converting y... [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "6000/6000 [==============================] - 24s 4ms/step - loss: 0.3209 - accuracy: 0.9124 - val_loss: 0.1785 - val_accuracy: 0.9469\n",
      "Test loss: 0.17852474749088287\n",
      "Test accuracy: 0.9469000101089478\n"
     ]
    }
   ],
   "source": [
    "# based on https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras.datasets.mnist as kdm\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU') # if you have an m1/m2 mac, uncomment this line to run wayyyy faster if you have local install of jupyter. leave commented if you are running on google colab \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)\n",
    "\n",
    "print(\"before converting...\", y_train[0])\n",
    "\n",
    "# reshape\n",
    "img_rows, img_cols = 28, 28\n",
    "# normalize inputs to between 0 and 1\n",
    "import numpy as np\n",
    "x_train = np.true_divide(x_train, 255)\n",
    "x_test = np.true_divide(x_test, 255)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "print(y_test[0])\n",
    "\n",
    "# convert to vector outputs \n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print(\"after converting y...\", y_test[0])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  layers.Flatten(input_shape=(28,28)),\n",
    "  layers.Dense(100, activation='sigmoid'),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=10,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save(\"test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xcK4luC5Zzmi"
   },
   "outputs": [],
   "source": [
    "def findTroublesomeImageKERAS(model, x_test):\n",
    "  worsta = 1\n",
    "  worsti = 0\n",
    "  for i in range(len(x_test)):\n",
    "    prediction = model.predict(x_test[i], verbose=False)\n",
    "    max_a = np.max(prediction)\n",
    "    if max_a < worsta:\n",
    "      worsta = max_a\n",
    "      worsti = i\n",
    "  return (worsta, worsti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvmAOO5OWTrG",
    "outputId": "1b5fdd4f-269b-42c8-f3fe-fa240b59bc56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17852474749088287, 0.9469000101089478]\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "[[5.2142653e-08 9.9365425e-01 3.1559356e-04 7.7011500e-04 8.1778135e-06\n",
      "  4.2704612e-04 1.7263803e-04 1.3467764e-04 4.2456985e-03 2.7185015e-04]]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(0.23342237, 2770)\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "#print(x_test[768])\n",
    "a = model.predict(x_test[768:769])\n",
    "print(a)\n",
    "print(y_test[768])\n",
    "troublesome = findTroublesomeImageKERAS(model, x_test)\n",
    "print(troublesome)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "f6qi6EKSfEN5",
    "outputId": "e4f7181d-1ed4-4363-ac74-e4555bc5cbcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[2.1933114e-04 6.9563421e-03 7.1216943e-03 2.3342237e-01 2.2985999e-01\n",
      "  7.8104213e-02 2.0286709e-01 8.0640174e-02 1.5241440e-01 8.3944304e-03]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1553782790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANSUlEQVR4nO3db6hc9Z3H8c/HmD7QNpJsriGkYrpFH+hC0zqGxYaSpVqjCEmfSPOgRBRTMJEWihiySOIT0XXTokYK6RqSXWpKoTEG1N1qCEhBihPJav5QdSXShHjvDcFoEawm331wj+Um3jlzM+fMnEm+7xcMM3O+c+b3ZcgnZ+45c87PESEAF79Lmm4AwGAQdiAJwg4kQdiBJAg7kMSlgxxs7ty5sXDhwkEOCaRy5MgRnThxwlPVKoXd9jJJT0iaIek/IuLRstcvXLhQ7Xa7ypAASrRarY61nr/G254h6WlJt0m6TtJK29f1+n4A+qvK3+yLJb0bEe9FxN8k/VbS8nraAlC3KmFfIOkvk54fLZadxfZq223b7fHx8QrDAaii73vjI2JLRLQiojUyMtLv4QB0UCXsxyRdNen514tlAIZQlbC/Luka29+w/RVJP5K0u562ANSt50NvEfG57bWS/kcTh962RsTB2joDUKtKx9kj4kVJL9bUC4A+4ueyQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQqTdls+4ikjyWdlvR5RLTqaApA/SqFvfAvEXGihvcB0Ed8jQeSqBr2kPQH2/tsr57qBbZX227bbo+Pj1ccDkCvqoZ9SUR8R9JtktbY/t65L4iILRHRiojWyMhIxeEA9KpS2CPiWHE/Juk5SYvraApA/XoOu+3LbX/ti8eSfiDpQF2NAahXlb3x8yQ9Z/uL93k2Iv67lq4A1K7nsEfEe5K+VWMvAPqIQ29AEoQdSIKwA0kQdiAJwg4kUceJMBeE+++/v7S+YMGC0vq6devqbAcYOLbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEmuPsmzdvLq1fckn5/3tvv/12x9rdd99duu6SJUtK68AgsGUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTSHGfvJiJK69u2betYe+mll0rXvfbaa3tpaSjMmjWrtL506dLS+u7du2vs5mybNm0qrbdaTCo8GVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC4+w1GB0drVS/kL3wwguNjf3AAw+U1vfu3TugTi4MXbfstrfaHrN9YNKyObZftv1OcT+7v20CqGo6X+O3SVp2zrJ1kvZExDWS9hTPAQyxrmGPiFclnTxn8XJJ24vH2yWtqLkvADXrdQfdvIg4Xjz+QNK8Ti+0vdp223Z7fHy8x+EAVFV5b3xMnEHS8SySiNgSEa2IaI2MjFQdDkCPeg37qO35klTcj9XXEoB+6DXsuyWtKh6vkvR8Pe0A6Jeux9lt75C0VNJc20clbZD0qKTf2b5H0vuS7uxnk3Xodm7zvn37BtQJ6sL56uena9gjYmWH0vdr7gVAH/FzWSAJwg4kQdiBJAg7kARhB5JIc4rrrl27SuuHDx8urT/77LMda/0+lfLo0aOl9dOnT/d1/Couu+yyjrWHHnqodN0bbrihtH7TTTf11FNWbNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIk0x9kXLFhQqX7zzTfX2c55mT27/OK9p06dGlAn52/+/Pkda5999lnpuk1+5hcjtuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kIQnJnQZjFarFe12e2DjXSwu5OPsZWyX1q+88spK73/ppZ1/RvL000+Xrrt06dLS+qxZs3ppqe9arZba7faUHyxbdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IIs357BeyHTt2lNYff/zxjrVDhw6VrnvixInSej+vSd/tNx6jo6N9G3vFihWl9bvuuqu0vnnz5tJ62fXym9J1y257q+0x2wcmLdto+5jt/cXt9v62CaCq6XyN3yZp2RTLfxkRi4rbi/W2BaBuXcMeEa9KOjmAXgD0UZUddGttv1l8ze/4423bq223bbfHx8crDAegil7D/itJ35S0SNJxSZs6vTAitkREKyJaIyMjPQ4HoKqewh4RoxFxOiLOSPq1pMX1tgWgbj2F3fbk6wP/UNKBTq8FMBy6Hme3vUPSUklzbR+VtEHSUtuLJIWkI5J+0sce01u2bKqDIdOvl3nsscdK65988knP713Va6+9Vlp/5ZVX+jb2tm3bSusffvhhaX3nzp01dlOPrmGPiJVTLH6mD70A6CN+LgskQdiBJAg7kARhB5Ig7EASnOKa3IMPPtjY2N2mbF67du2AOjl/u3btarqF88aWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dj7ReDMmTMdax999FHpujNnzqw0drdj5WWXsi67BLYkPf/88z31VIey6Z4lac2aNQPqpD5s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCY6zXwCefPLJ0vrY2FjH2iOPPFK67vXXX19a7zatcrcpoS9U69evL61v3LhxMI3UiC07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfYLwIYNG0rrp06d6vm9Dx482PO6TbviiitK6zfeeGPH2ubNm0vXvfrqq3vqaZh13bLbvsr2XtuHbB+0/dNi+RzbL9t+p7if3f92AfRqOl/jP5f084i4TtI/S1pj+zpJ6yTtiYhrJO0pngMYUl3DHhHHI+KN4vHHkg5LWiBpuaTtxcu2S1rRryYBVHdeO+hsL5T0bUl/kjQvIo4XpQ8kzeuwzmrbbdvt8fHxCq0CqGLaYbf9VUm/l/SziDjrKoYxcbbElGdMRMSWiGhFRGtkZKRSswB6N62w256piaD/JiJ2FotHbc8v6vMldT71CkDjuh56s21Jz0g6HBG/mFTaLWmVpEeL++au+3uRu/fee0vrTz31VMfap59+Wnc7Z+l2KeoZM2b0/N633npraf2+++4rrd9yyy09j30xms5x9u9K+rGkt2zvL5at10TIf2f7HknvS7qzPy0CqEPXsEfEHyW5Q/n79bYDoF/4uSyQBGEHkiDsQBKEHUiCsANJuNulguvUarWi3W4PbLwsTp482bH28MMP93Xsbsey77jjjr6Oj7O1Wi212+0pj56xZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJLiU9EVgzpw5HWtPPPHEADvBMGPLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0l0Dbvtq2zvtX3I9kHbPy2Wb7R9zPb+4nZ7/9sF0KvpXLzic0k/j4g3bH9N0j7bLxe1X0bEv/evPQB1mc787MclHS8ef2z7sKQF/W4MQL3O62922wslfVvSn4pFa22/aXur7dkd1lltu227PT4+XqlZAL2bdthtf1XS7yX9LCI+kvQrSd+UtEgTW/5NU60XEVsiohURrZGRkRpaBtCLaYXd9kxNBP03EbFTkiJiNCJOR8QZSb+WtLh/bQKoajp74y3pGUmHI+IXk5bPn/SyH0o6UH97AOoynb3x35X0Y0lv2d5fLFsvaaXtRZJC0hFJP+lLhwBqMZ298X+UNNV8zy/W3w6AfuEXdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQcEYMbzB6X9P6kRXMlnRhYA+dnWHsb1r4keutVnb1dHRFTXv9toGH/0uB2OyJajTVQYlh7G9a+JHrr1aB642s8kARhB5JoOuxbGh6/zLD2Nqx9SfTWq4H01ujf7AAGp+ktO4ABIexAEo2E3fYy23+2/a7tdU300IntI7bfKqahbjfcy1bbY7YPTFo2x/bLtt8p7qecY6+h3oZiGu+SacYb/eyanv584H+z254h6W1Jt0g6Kul1SSsj4tBAG+nA9hFJrYho/AcYtr8n6a+S/jMi/qlY9m+STkbEo8V/lLMj4sEh6W2jpL82PY13MVvR/MnTjEtaIekuNfjZlfR1pwbwuTWxZV8s6d2IeC8i/ibpt5KWN9DH0IuIVyWdPGfxcknbi8fbNfGPZeA69DYUIuJ4RLxRPP5Y0hfTjDf62ZX0NRBNhH2BpL9Men5UwzXfe0j6g+19tlc33cwU5kXE8eLxB5LmNdnMFLpO4z1I50wzPjSfXS/Tn1fFDrovWxIR35F0m6Q1xdfVoRQTf4MN07HTaU3jPShTTDP+d01+dr1Of15VE2E/JumqSc+/XiwbChFxrLgfk/Schm8q6tEvZtAt7sca7ufvhmka76mmGdcQfHZNTn/eRNhfl3SN7W/Y/oqkH0na3UAfX2L78mLHiWxfLukHGr6pqHdLWlU8XiXp+QZ7OcuwTOPdaZpxNfzZNT79eUQM/Cbpdk3skf8/Sf/aRA8d+vpHSf9b3A423ZukHZr4WveZJvZt3CPpHyTtkfSOpFckzRmi3v5L0luS3tREsOY31NsSTXxFf1PS/uJ2e9OfXUlfA/nc+LkskAQ76IAkCDuQBGEHkiDsQBKEHUiCsANJEHYgif8HvIkKYr5HOakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = model.predict(x_test[2770])\n",
    "print(a)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(np.reshape(x_test[2770], (28,28)),cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuVsMZaqdqKK",
    "outputId": "d3a11a71-d2dd-421f-8439-656c79540e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def dec_to_binvector4(dec):\n",
    "  binstr = \"{0:04b}\".format(int(dec))\n",
    "  binvect = []\n",
    "  for b in binstr:\n",
    "    binvect.append(int(b))\n",
    "  return binvect\n",
    "\n",
    "# expects y_data to be a list of nonnegative integer numbers (e.g., 0, 1, 2, 3)\n",
    "# returns the binary representation of each y using the specified number of bits\n",
    "def to_binary(y_data):\n",
    "  return [np.array(dec_to_binvector4(y)).reshape(4, 1) for y in y_data]\n",
    "\n",
    "print(dec_to_binvector4(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hi76OiM6hyY2",
    "outputId": "895dc1bc-3a56-46c0-abb6-ab12a7e34d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6000/6000 [==============================] - 15s 2ms/step - loss: 0.0660 - accuracy: 0.5081 - val_loss: 0.0295 - val_accuracy: 0.5883\n",
      "Epoch 2/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0228 - accuracy: 0.5585 - val_loss: 0.0189 - val_accuracy: 0.5533\n",
      "Epoch 3/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0158 - accuracy: 0.5744 - val_loss: 0.0159 - val_accuracy: 0.5755\n",
      "Epoch 4/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0125 - accuracy: 0.5897 - val_loss: 0.0142 - val_accuracy: 0.6000\n",
      "Epoch 5/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0104 - accuracy: 0.6041 - val_loss: 0.0132 - val_accuracy: 0.5979\n",
      "Epoch 6/30\n",
      "6000/6000 [==============================] - 15s 3ms/step - loss: 0.0087 - accuracy: 0.6034 - val_loss: 0.0137 - val_accuracy: 0.6168\n",
      "Epoch 7/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0075 - accuracy: 0.6212 - val_loss: 0.0125 - val_accuracy: 0.6261\n",
      "Epoch 8/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0067 - accuracy: 0.6314 - val_loss: 0.0130 - val_accuracy: 0.6143\n",
      "Epoch 9/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0059 - accuracy: 0.6343 - val_loss: 0.0129 - val_accuracy: 0.6456\n",
      "Epoch 10/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0052 - accuracy: 0.6444 - val_loss: 0.0121 - val_accuracy: 0.6667\n",
      "Epoch 11/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0047 - accuracy: 0.6504 - val_loss: 0.0118 - val_accuracy: 0.6149\n",
      "Epoch 12/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0042 - accuracy: 0.6550 - val_loss: 0.0124 - val_accuracy: 0.6433\n",
      "Epoch 13/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0038 - accuracy: 0.6623 - val_loss: 0.0121 - val_accuracy: 0.6417\n",
      "Epoch 14/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0035 - accuracy: 0.6601 - val_loss: 0.0119 - val_accuracy: 0.6574\n",
      "Epoch 15/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0032 - accuracy: 0.6607 - val_loss: 0.0120 - val_accuracy: 0.6758\n",
      "Epoch 16/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0030 - accuracy: 0.6713 - val_loss: 0.0128 - val_accuracy: 0.6555\n",
      "Epoch 17/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0028 - accuracy: 0.6646 - val_loss: 0.0122 - val_accuracy: 0.6372\n",
      "Epoch 18/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0025 - accuracy: 0.6693 - val_loss: 0.0119 - val_accuracy: 0.6673\n",
      "Epoch 19/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0024 - accuracy: 0.6741 - val_loss: 0.0124 - val_accuracy: 0.6676\n",
      "Epoch 20/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0023 - accuracy: 0.6700 - val_loss: 0.0127 - val_accuracy: 0.6642\n",
      "Epoch 21/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0022 - accuracy: 0.6745 - val_loss: 0.0127 - val_accuracy: 0.6359\n",
      "Epoch 22/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0021 - accuracy: 0.6684 - val_loss: 0.0124 - val_accuracy: 0.6697\n",
      "Epoch 23/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0019 - accuracy: 0.6721 - val_loss: 0.0121 - val_accuracy: 0.6678\n",
      "Epoch 24/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0019 - accuracy: 0.6722 - val_loss: 0.0128 - val_accuracy: 0.6691\n",
      "Epoch 25/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0018 - accuracy: 0.6726 - val_loss: 0.0130 - val_accuracy: 0.6435\n",
      "Epoch 26/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0017 - accuracy: 0.6760 - val_loss: 0.0131 - val_accuracy: 0.6866\n",
      "Epoch 27/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0016 - accuracy: 0.6733 - val_loss: 0.0127 - val_accuracy: 0.6589\n",
      "Epoch 28/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0016 - accuracy: 0.6737 - val_loss: 0.0131 - val_accuracy: 0.6775\n",
      "Epoch 29/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0015 - accuracy: 0.6789 - val_loss: 0.0131 - val_accuracy: 0.6637\n",
      "Epoch 30/30\n",
      "6000/6000 [==============================] - 14s 2ms/step - loss: 0.0014 - accuracy: 0.6754 - val_loss: 0.0131 - val_accuracy: 0.6957\n",
      "Test loss: 0.01314517855644226\n",
      "Test accuracy: 0.6956999897956848\n"
     ]
    }
   ],
   "source": [
    "# based on https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras.datasets.mnist as kdm\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
    "\n",
    "\n",
    "# reshape\n",
    "img_rows, img_cols = 28, 28\n",
    "# normalize inputs to between 0 and 1\n",
    "import numpy as np\n",
    "x_train = np.true_divide(x_train, 255)\n",
    "x_test = np.true_divide(x_test, 255)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# convert to vector outputs \n",
    "num_classes = 10\n",
    "y_train = to_binary(y_train)\n",
    "y_test = to_binary(y_test)\n",
    "\n",
    "y_train = np.array(y_train).reshape(60000, 4)\n",
    "y_test = np.array(y_test).reshape(10000, 4)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  layers.Flatten(input_shape=(28,28)),\n",
    "  layers.Dense(100, activation='sigmoid'),\n",
    "  layers.Dense(10, activation='sigmoid'),\n",
    "  layers.Dense(4, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=10,\n",
    "          epochs=30,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save(\"test_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
